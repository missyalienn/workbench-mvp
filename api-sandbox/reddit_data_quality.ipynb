{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8831f1ab",
   "metadata": {},
   "source": [
    "## Reddit Data Pipeline QC\n",
    "\n",
    "Purpose: Explore methods to filter and clean subreddit data to create a meaningful DIY/home improvement dataset for Workbench RAG pipeline.\n",
    "\n",
    "## Topics\n",
    "1. Fetch subreddit posts by flair\n",
    "2. Filter posts by keywords\n",
    "3. Define minimum viable fetch posts function for data pipeline\n",
    "4. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c2d8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User agent: TestScript/1.0 by /u/chippetto90\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import sample \n",
    "import praw\n",
    "import keyring \n",
    "from praw.models import user\n",
    "import time\n",
    "\n",
    "# Reddit API Auth using Keychain Creds \n",
    "client_id = keyring.get_password(\"reddit-client-id\", \"reddit-api\")\n",
    "client_secret = keyring.get_password(\"reddit-client-secret\", \"reddit-api\")\n",
    "user_agent = \"TestScript/1.0 by /u/chippetto90\"\n",
    "\n",
    "# Initialize Reddit client\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent,\n",
    ")\n",
    "\n",
    "print(\"User agent:\", user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3976cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching top 5 posts from r/diy...\n",
      "Post 1 title: My wife went to a work event for a few days, in my hubris I thought I could build her a new studio before she got back...\n",
      "Post 2 title: My Christmas present to my wife this year was renovating our laundry room. How did I do?\n",
      "Post 3 title: Wife put me in charge of wedding favors and I needed a project.\n",
      "Post 4 title: Made a bulldozer bed for my 2yo\n",
      "Post 5 title: 4 months ago I lost all respect for local contractors. 4 months later I've gained a ton for myself.\n",
      "Successfully fetched 5 posts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Submission(id='1jjxjn6'),\n",
       " Submission(id='1homo1x'),\n",
       " Submission(id='1h4kt3o'),\n",
       " Submission(id='1lfa89a'),\n",
       " Submission(id='1nvc72e')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def fetch_posts(reddit, limit=5):\n",
    "    \"\"\"Fetch top posts from r/diy subreddit with rate limiting.\"\"\"\n",
    "    print(f\"Fetching top {limit} posts from r/diy...\")\n",
    "    posts_list = []\n",
    "    subreddit = reddit.subreddit(\"diy\")\n",
    "    \n",
    "    for i, submission in enumerate(subreddit.top(time_filter=\"year\", limit=limit)):\n",
    "        posts_list.append(submission)\n",
    "        print(f\"Post {i + 1} title: {submission.title}\")  # <- added line\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Fetched {i + 1} posts...\")\n",
    "        time.sleep(1.2)  # Respect Reddit API limits\n",
    "    \n",
    "    print(f\"Successfully fetched {len(posts_list)} posts\")\n",
    "    return posts_list\n",
    "\n",
    "fetch_posts(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d435bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch posts by flair and title keywords \n",
    "\n",
    "def fetch_flair_posts(\n",
    "    reddit, \n",
    "    subreddit_name=\"diy\", \n",
    "    flair=None, \n",
    "    limit=10, \n",
    "    sample_size=50, \n",
    "    keywords=None,\n",
    "    delay=0.5 #default sleep between requests\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch top posts from a subreddit filtered by flair and optional title keywords.\n",
    "    \n",
    "    Parameters:\n",
    "    - reddit: authenticated PRAW Reddit instance\n",
    "    - subreddit_name: subreddit to fetch from (default 'diy')\n",
    "    - flair: text of the flair to filter by (case-insensitive)\n",
    "    - limit: max number of posts to return\n",
    "    - sample_size: number of top posts to sample from\n",
    "    - keywords: list of keywords to filter titles (case-insensitive)\n",
    "    \n",
    "    Returns:\n",
    "    - List of PRAW Submission objects\n",
    "    \"\"\"\n",
    "    posts_list = []\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    \n",
    "    if keywords is None:\n",
    "        keywords = []  # empty list means no keyword filtering\n",
    "\n",
    "    print(f\"Fetching up to {limit} posts from {subreddit_name} with flair: {flair}. Sample size = {sample_size} top posts...\\n\")\n",
    "    \n",
    "    for submission in subreddit.top(time_filter=\"year\", limit=sample_size):\n",
    "        title_lower = submission.title.lower()\n",
    "        flair_match = (flair is None) or (submission.link_flair_text and submission.link_flair_text.lower() == flair.lower())\n",
    "        keyword_match = (not keywords) or any(kw.lower() in title_lower for kw in keywords)\n",
    "        \n",
    "        if flair_match and keyword_match:\n",
    "            posts_list.append(submission)\n",
    "            if len(posts_list) >= limit:\n",
    "                break\n",
    "        time.sleep(delay)  # Respect Reddit API rate limits\n",
    "\n",
    "    print(f\"\\nDone! Collected {len(posts_list)} posts.\\n\")\n",
    "    return posts_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d4f266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching up to 10 posts from diy with flair: home improvement. Sample size = 100 top posts...\n",
      "\n",
      "\n",
      "Done! Collected 10 posts.\n",
      "\n",
      "- My wife went to a work event for a few days, in my hubris I thought I could buil | Flair: home improvement\n",
      "- My Christmas present to my wife this year was renovating our laundry room. How d | Flair: home improvement\n",
      "- Finished the 2nd floor of my garage into a Home Theatre and Gym. | Flair: home improvement\n",
      "- My VHS collection got too big so I decided to build my own Blockbuster inside of | Flair: home improvement\n",
      "- Only took all summer… finally stained my garage door. | Flair: home improvement\n",
      "- New laundry nook in our 150yr old house! After/Before and Full Process | Flair: home improvement\n",
      "- Upcycled some bowling alley lanes for flooring in my renovation project! | Flair: home improvement\n",
      "- 2 days and $200 later, a quick guest bathroom makeover on our 1927 home. | Flair: home improvement\n",
      "- Laid a full wall of herringbone tile wrong. Now what? | Flair: home improvement\n",
      "- First Bathroom Remodel  | Flair: home improvement\n"
     ]
    }
   ],
   "source": [
    "#flair= \"home improvement\" \n",
    "#Fetch r/diy posts with flair: home improvement\n",
    "\n",
    "posts = fetch_flair_posts(\n",
    "    reddit, \n",
    "    flair=\"home improvement\",\n",
    "    keywords=None,\n",
    "    limit=10, \n",
    "    sample_size=100,\n",
    "    delay=0.3\n",
    ")\n",
    "\n",
    "for post in posts: \n",
    "     print(f\"- {post.title[:80]} | Flair: {post.link_flair_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "974c88bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching up to 10 posts from diy with flair: help. Sample size = 100 top posts...\n",
      "\n",
      "\n",
      "Done! Collected 5 posts.\n",
      "\n",
      "- Not sure if this is the right audience | Flair: help\n",
      "- We had wedding guests sign a whiskey barrel as a memento. What's the best way to | Flair: help\n",
      "- Duct covering | Flair: help\n",
      "- How bad is this? | Flair: help\n",
      "- Update: Laid a full wall of herringbone tile wrong. Now what? | Flair: help\n"
     ]
    }
   ],
   "source": [
    "#flair= \"help\"\n",
    "#Fetch r/diy posts with flair: help \n",
    "\n",
    "posts = fetch_flair_posts(\n",
    "    reddit, \n",
    "    flair=\"help\",\n",
    "    keywords=None,\n",
    "    limit=10, \n",
    "    sample_size=100\n",
    ")\n",
    "\n",
    "for post in posts: \n",
    "     print(f\"- {post.title[:80]} | Flair: {post.link_flair_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimal Keyword Filtering Test \n",
    "#See how many posts in given sample of subreddit contain a given keyword. \n",
    "\n",
    "subreddit = reddit.subreddit(\"diy\")\n",
    "sample_posts = list(subreddit.top(time_filter=\"year\", limit=20))  # small sample\n",
    "\n",
    "#Test Keyword: \n",
    "keywords = [\"my\"]  \n",
    "\n",
    "matches = []\n",
    "for post in sample_posts:\n",
    "    match = any(kw.lower() in post.title.lower() for kw in keywords)\n",
    "    print(f\"Title: {post.title[:60]} | Match: {match}\")  # debug each post\n",
    "    if match:\n",
    "        matches.append(post)\n",
    "\n",
    "print(\"\\nPosts with Keyword Match:\")\n",
    "for post in matches:\n",
    "    print(f\"- {post.title[:80]} | Flair: {post.link_flair_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: My wife went to a work event for a few days, in my hubris I  | Match: True\n",
      "Title: My Christmas present to my wife this year was renovating our | Match: True\n",
      "Title: Wife put me in charge of wedding favors and I needed a proje | Match: False\n",
      "Title: Made a bulldozer bed for my 2yo | Match: True\n",
      "Title: 4 months ago I lost all respect for local contractors. 4 mon | Match: True\n",
      "Title: Rental Remodel After Nightmare Tenant  | Match: False\n",
      "Title: Not sure if this is the right audience | Match: False\n",
      "Title: Wife said I should just use wood filler, I had a better idea | Match: False\n",
      "Title: Was tired of my janky walkout - added deck tiles and paint | Match: True\n",
      "Title: Finished the 2nd floor of my garage into a Home Theatre and  | Match: True\n",
      "Title: My VHS collection got too big so I decided to build my own B | Match: True\n",
      "Title: She Shed build for the wife in 2021 | Match: False\n",
      "Title: Only took all summer… finally stained my garage door. | Match: True\n",
      "Title: Update: 12ft Wendy’s Sign in Our College Backyard | Match: False\n",
      "Title: New laundry nook in our 150yr old house! After/Before and Fu | Match: False\n",
      "Title: 3 year garage/studio apartment build, cost ~$70,000 and one  | Match: False\n",
      "Title: Upcycled some bowling alley lanes for flooring in my renovat | Match: True\n",
      "Title: 2 days and $200 later, a quick guest bathroom makeover on ou | Match: False\n",
      "Title: Wife wanted to spend $10 on a faucet extender for our son to | Match: True\n",
      "Title: Laid a full wall of herringbone tile wrong. Now what? | Match: False\n",
      "\n",
      "Summary:\n",
      "Total posts sampled: 20\n",
      "Posts matching keyword: 10\n",
      "Percent matching: 50.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Keyword Filtering Test with Stats\n",
    "\n",
    "subreddit = reddit.subreddit(\"diy\")\n",
    "sample_posts = list(subreddit.top(time_filter=\"year\", limit=20))  # small sample for testing\n",
    "\n",
    "# Keywords to Test: \n",
    "keywords = [\"my\"]  # just to see if filtering works\n",
    "\n",
    "# Track matches\n",
    "matches = []\n",
    "\n",
    "for post in sample_posts:\n",
    "    match = any(kw.lower() in post.title.lower() for kw in keywords)\n",
    "    matches.append(match)\n",
    "    print(f\"Title: {post.title[:60]} | Match: {match}\")\n",
    "\n",
    "# Calculate stats\n",
    "total = len(matches)\n",
    "true_count = sum(matches)\n",
    "percent_true = true_count / total * 100 if total else 0\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total posts sampled: {total}\")\n",
    "print(f\"Posts matching keyword: {true_count}\")\n",
    "print(f\"Percent matching: {percent_true:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de334e",
   "metadata": {},
   "source": [
    "## Results of Flair Only Tests\n",
    "\n",
    "- **Home Improvement Flair (Top 100 posts)**  \n",
    "  - Returned 10 posts, but most were project showcases rather than instructional/how-to content.  \n",
    "\n",
    "- **Help Flair (Top 100 posts)**  \n",
    "  - Returned 5 posts.  \n",
    "  - Some posts were actual questions or \"how-to\" style, others were situational/context-based.  \n",
    "\n",
    "**Key Takeaways:**  \n",
    "- Flair-only filtering works but **does not guarantee instructional content**.  \n",
    "- Some flairs (like \"help\") are **sparse in top posts**, limiting relevant content.  \n",
    "- To improve recall, consider **combining flair + keyword search in title and body** or using **PRAW search queries** directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf167c",
   "metadata": {},
   "source": [
    "## MVF - Minimum Viable Fetch for MVP\n",
    "\n",
    "To get a working end-to-end RAG pipeline sooner rather than later, we define a **minimal fetch function**.  \n",
    "\n",
    "This function acts as a **placeholder** for MVP development allowing us to ingest posts, embed text w/ OpenAI embeddings API, implement vector storage, implement retrieval, and **test the full pipeline** without over-optimizing for data quality first. \n",
    "\n",
    "### Minimum Viable Fetch Requirements\n",
    "\n",
    "- Fetches top posts from a subreddit, optionally filtered by flair. \n",
    "\n",
    "- Designed to be **fast and simple**: no keyword or body filtering yet. \n",
    "  \n",
    "- Add print_titles flag - quickly see what posts were fetched w/o looping through manually everytime. \n",
    "\n",
    " ``` python\n",
    "        if print_titles:\n",
    "        print(f\"- {submission.title[:80]} | Flair: {submission.link_flair_text}\")\n",
    "```\n",
    "- Return a simple summary: Like {\"posts\": posts_list, \"count\": len(posts_list)}. Easier to log stats in testing/notebook. \n",
    "\n",
    "- Parameterize `time_filter` - defaulting to `year`, but need to extend to allow `all`, `month`, etc. \n",
    "- Rate-limiting parameter - make the `delay` adjustable per call so we can speed up or slow down without editing function itself everytime\n",
    "- Update docstring to note that this is the placeholder fetch for this mvp. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf16b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimum Viable Fetch Function \n",
    "\n",
    "def fetch_mvp_posts(\n",
    "    reddit, \n",
    "    subreddit_name=\"diy\", \n",
    "    flair=None, \n",
    "    limit=10, \n",
    "    sample_size=50, \n",
    "    delay=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal fetch for MVP: grab top posts with optional flair.\n",
    "    No keyword filtering yet — we just want enough posts to test RAG pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    - reddit: authenticated PRAW instance\n",
    "    - subreddit_name: str\n",
    "    - flair: str or None (optional)\n",
    "    - limit: max posts to return\n",
    "    - sample_size: top posts to sample\n",
    "    - delay: seconds to sleep between API calls\n",
    "    \"\"\"\n",
    "    posts_list = []\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    \n",
    "    for submission in subreddit.top(time_filter=\"year\", limit=sample_size):\n",
    "        if flair is None or (submission.link_flair_text and submission.link_flair_text.lower() == flair.lower()):\n",
    "            posts_list.append(submission)\n",
    "            if len(posts_list) >= limit:\n",
    "                break\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(f\"Fetched {len(posts_list)} posts from r/{subreddit_name} with flair={flair}\")\n",
    "    return posts_list\n",
    "\n",
    "# Example call for MVP\n",
    "mvp_posts = fetch_mvp_posts(reddit, flair=\"help\", limit=10, sample_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Minimum Viable Function Call: \n",
    "\n",
    "# Minimal example, flair only\n",
    "results = fetch_mvp_posts(reddit, flair=\"home improvement\", limit=5, sample_size=50)\n",
    "\n",
    "# Access posts list\n",
    "posts = results[\"posts\"]\n",
    "print(\"Number of posts collected:\", results[\"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21342c4",
   "metadata": {},
   "source": [
    "### 💡 Next Steps After MVP\n",
    "\n",
    "- Add a Keyword stats wrapper function: count matches, calculate percentages.\n",
    "- Add Text/body filtering: include post body for richer “how-to” detection.\n",
    "- Define modular data eval framework: to determine best data filtering methods to product high quality dataset for future scaling\n",
    "- RAG integration: feed these posts into embeddings → vector DB → retrieval pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea559e67",
   "metadata": {},
   "source": [
    "#### Example: Lightweight keyword stats wrapper\n",
    "\n",
    "Works with `fetch_posts_mvp()` output. Can be extended later with more keywords, flair combos, more complex rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4396c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_stats(posts_dict, keywords):\n",
    "    \"\"\"\n",
    "    Evaluate posts against a list of keywords in their titles.\n",
    "\n",
    "    Parameters:\n",
    "    - posts_dict: dict returned by fetch_mvp_posts (must have 'posts' list)\n",
    "    - keywords: list of strings to search for in post titles (case-insensitive)\n",
    "\n",
    "    Returns:\n",
    "    - dict with:\n",
    "        - total_posts: int, total number of posts checked\n",
    "        - matches: int, number of posts containing at least one keyword\n",
    "        - match_pct: float, percentage of posts matching keywords\n",
    "        - matched_titles: list of matched post titles\n",
    "    \"\"\"\n",
    "    posts = posts_dict.get(\"posts\", [])\n",
    "    matched_titles = []\n",
    "\n",
    "    for post in posts:\n",
    "        title_lower = post.title.lower()\n",
    "        if any(kw.lower() in title_lower for kw in keywords):\n",
    "            matched_titles.append(post.title)\n",
    "\n",
    "    total_posts = len(posts)\n",
    "    matches = len(matched_titles)\n",
    "    match_pct = (matches / total_posts * 100) if total_posts else 0.0\n",
    "\n",
    "    print(f\"\\nKeyword stats:\")\n",
    "    print(f\"Total posts checked: {total_posts}\")\n",
    "    print(f\"Posts matching keywords {keywords}: {matches}\")\n",
    "    print(f\"Percentage match: {match_pct:.1f}%\\n\")\n",
    "    \n",
    "    if matched_titles:\n",
    "        print(\"Matched post titles:\")\n",
    "        for t in matched_titles:\n",
    "            print(f\"- {t[:80]}...\")  # truncate for notebook display\n",
    "\n",
    "    return {\n",
    "        \"total_posts\": total_posts,\n",
    "        \"matches\": matches,\n",
    "        \"match_pct\": match_pct,\n",
    "        \"matched_titles\": matched_titles\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
